import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import IsolationForest
import re
import warnings

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ù†Ø¸Ø§ÙØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
warnings.filterwarnings('ignore')

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (UI/UX)
# ==========================================
st.set_page_config(
    page_title="Enterprise AI Analyst",
    layout="wide",
    page_icon="ğŸ§ ",
    initial_sidebar_state="expanded"
)

# ØªØ­Ø³ÙŠÙ† Ù…Ø¸Ù‡Ø± Ø§Ù„Ø´Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CSS
st.markdown("""
<style>
    .stChatInput {
        position: fixed;
        bottom: 20px;
        z-index: 1000;
    }
    .block-container {
        padding-bottom: 100px;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠ (Auto-Detection Engine)
# ==========================================
class AutoIdentifier:
    def __init__(self, df):
        self.df = df.copy()
        self.roles = {
            'date_col': None,
            'target_col': None,
            'cat_cols': []
        }
        self._detect_roles()

    def _detect_roles(self):
        # 1. ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        self.df.columns = [str(c).strip() for c in self.df.columns]
        cols = self.df.columns
        
        # Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
        keywords = {
            'date': ['date', 'time', 'ØªØ§Ø±ÙŠØ®', 'ÙˆÙ‚Øª', 'Ø²Ù…Ù†', 'ÙŠÙˆÙ…', 'Ø´Ù‡Ø±'],
            'money_qty': ['price', 'sales', 'amount', 'total', 'salary', 'revenue', 'profit', 'cost', 'qty', 'stock', 
                          'Ø³Ø¹Ø±', 'Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ù…Ø¨Ù„Øº', 'Ø§Ø¬Ù…Ø§Ù„ÙŠ', 'Ø±Ø§ØªØ¨', 'Ø±Ø¨Ø­', 'ØªÙƒÙ„ÙØ©', 'Ø±ØµÙŠØ¯', 'Ù‚ÙŠÙ…Ø©', 'ÙƒÙ…ÙŠØ©', 'Ù…Ø®Ø²ÙˆÙ†', 'Ø¹Ø¯Ø¯']
        }

        # A. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
        for col in cols:
            # Ù„Ùˆ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø£ØµÙ„Ø§Ù‹ Ù†ÙˆØ¹Ù‡ ØªØ§Ø±ÙŠØ®
            if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                self.roles['date_col'] = col
                break
            # Ù„Ùˆ Ø§Ù„Ø§Ø³Ù… ÙŠÙˆØ­ÙŠ Ø¨ØªØ§Ø±ÙŠØ®ØŒ Ù†Ø­Ø§ÙˆÙ„ Ù†Ø­ÙˆÙ„Ù‡
            if any(k in col.lower() for k in keywords['date']):
                try:
                    self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
                    # Ù†ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ø§ØªØ­ÙˆÙ„ ÙØ¹Ù„Ø§Ù‹
                    if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                        self.roles['date_col'] = col
                        break
                except: pass

        # B. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø±Ù‚Ù…ÙŠ (Target)
        potential_targets = []
        for col in cols:
            # Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ø±Ù‚Ù…ÙŠ
            if pd.api.types.is_numeric_dtype(self.df[col]):
                score = 0
                if any(k in col.lower() for k in keywords['money_qty']): score += 2
                # Ù†ÙØ¶Ù„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡ Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø© ÙƒØªÙŠØ± (Ø¹Ø´Ø§Ù† Ù…Ø´ ÙŠÙƒÙˆÙ† ID Ø£Ùˆ ÙƒÙˆØ¯)
                if self.df[col].nunique() > 5: score += 1
                potential_targets.append((col, score))
        
        if potential_targets:
            # Ù†Ø®ØªØ§Ø± ØµØ§Ø­Ø¨ Ø£Ø¹Ù„Ù‰ Ø³ÙƒÙˆØ±
            potential_targets.sort(key=lambda x: x[1], reverse=True)
            self.roles['target_col'] = potential_targets[0][0]

        # C. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª (Categories)
        for col in cols:
            if col == self.roles['date_col'] or col == self.roles['target_col']:
                continue
            # Ù†Ø¹ØªØ¨Ø±Ù‡ ØªØµÙ†ÙŠÙ Ù„Ùˆ Ù‡Ùˆ Ù†ØµÙŠ ÙˆØ¹Ø¯Ø¯ Ù‚ÙŠÙ…Ù‡ Ù…Ø¹Ù‚ÙˆÙ„
            if self.df[col].dtype == 'object' or pd.api.types.is_string_dtype(self.df[col]):
                if self.df[col].nunique() < 2000: # Ø±Ù‚Ù… ØªÙ‚Ø¯ÙŠØ±ÙŠ
                    self.roles['cat_cols'].append(col)

# ==========================================
# 3. Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø°ÙƒÙŠ (Analytical Brain)
# ==========================================
class SmartAnalyst:
    def __init__(self, df, roles):
        self.df = df
        self.roles = roles
        self.target = roles['target_col']
        self.date_col = roles['date_col']
        self.cats = roles['cat_cols']

    def process_query(self, query):
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if not self.target:
            return "âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ù„Ù„Ø£Ø±Ù‚Ø§Ù… (Ù…Ø¨ÙŠØ¹Ø§Øª/Ø±ÙˆØ§ØªØ¨/ÙƒÙ…ÙŠØ§Øª) ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ù„Ù.", None

        query = query.lower()
        filtered_df = self.df.copy()
        filters_applied = []

        # 1. Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        for cat in self.cats:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚ÙŠÙ… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø¯Ø§Ø®Ù„ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            unique_vals = self.df[cat].dropna().unique()
            for val in unique_vals:
                val_str = str(val).lower()
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…Ø© Ù„Ù„Ø¨Ø­Ø«
                if len(val_str) > 1 and val_str in query:
                    mask = filtered_df[cat].astype(str).str.contains(val_str, case=False, na=False)
                    if mask.any():
                        filtered_df = filtered_df[mask]
                        filters_applied.append(f"{val}")
                        break # Ù†ÙƒØªÙÙŠ Ø¨Ù‚ÙŠÙ…Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ù†ÙØ³ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªØ¶Ø§Ø±Ø¨

        context = f" (ÙÙŠ: {' + '.join(filters_applied)})" if filters_applied else " (Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ)"
        
        # 2. ÙÙ‡Ù… Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ (Intent)

        # --- Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ / Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ ---
        if any(x in query for x in ['Ø§Ø¬Ù…Ø§Ù„ÙŠ', 'Ù…Ø¬Ù…ÙˆØ¹', 'total', 'sum', 'ÙƒÙ…']):
            val = filtered_df[self.target].sum()
            return f"ğŸ’° **Ø¥Ø¬Ù…Ø§Ù„ÙŠ {self.target}** {context}:\n# {val:,.2f}", None

        # --- Ø§Ù„Ù…ØªÙˆØ³Ø· ---
        elif any(x in query for x in ['Ù…ØªÙˆØ³Ø·', 'Ù…Ø¹Ø¯Ù„', 'avg', 'average']):
            val = filtered_df[self.target].mean()
            return f"ğŸ“Š **Ù…ØªÙˆØ³Ø· {self.target}** {context}:\n# {val:,.2f}", None

        # --- Ø§Ù„Ø£ÙØ¶Ù„ / Ø§Ù„Ø£Ø¹Ù„Ù‰ ---
        elif any(x in query for x in ['Ø§ÙØ¶Ù„', 'Ø§Ø¹Ù„Ù‰', 'Ø§ÙƒØ«Ø±', 'top', 'best', 'max']):
            if self.cats:
                # Ù†Ø®ØªØ§Ø± Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ ØªØµÙ†ÙŠÙ Ù…Ù†Ø§Ø³Ø¨ (Ø£Ùˆ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù„ÙŠ ØªÙ… Ø§Ù„ÙÙ„ØªØ±Ø© Ø¹Ù„ÙŠÙ‡ Ù„Ùˆ Ù…ÙÙŠØ´ ØºÙŠØ±Ù‡)
                group_col = self.cats[0]
                # Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø³Ø£Ù„ Ø¹Ù† ØªØµÙ†ÙŠÙ Ù…Ø­Ø¯Ø¯ (Ù…Ø«Ù„Ø§Ù‹ "Ø£ÙØ¶Ù„ Ù…ÙˆØ¸Ù") Ù†Ø­Ø§ÙˆÙ„ Ù†Ù„Ø§Ù‚ÙŠÙ‡
                for c in self.cats:
                    if c.lower() in query:
                        group_col = c
                        break
                
                top = filtered_df.groupby(group_col)[self.target].sum().sort_values(ascending=False).head(5)
                fig = px.bar(top, x=top.index, y=self.target, title=f"Top 5 - {group_col}", color=self.target)
                return f"ğŸ† **Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡Ù‹** {context}:", fig
            else:
                val = filtered_df[self.target].max()
                return f"ğŸš€ **Ø£Ø¹Ù„Ù‰ Ø±Ù‚Ù… Ù…Ø³Ø¬Ù„:** {val:,.2f}", None

        # --- Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø²Ù…Ù†ÙŠ (Time Series) ---
        elif any(x in query for x in ['ØªØ·ÙˆØ±', 'Ø²Ù…Ù†', 'ØªØ§Ø±ÙŠØ®', 'trend', 'time', 'date']) and self.date_col:
            # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ù…Ø±ØªØ¨Ø©
            trend = filtered_df.sort_values(self.date_col)
            fig = px.line(trend, x=self.date_col, y=self.target, title=f"{self.target} Trend")
            return f"ğŸ“ˆ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ** {context}:", fig

        # --- Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ / Ø§Ù„Ø´ÙˆØ§Ø° (Anomaly) ---
        elif any(x in query for x in ['Ø®Ø·Ø£', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø´Ø§Ø°', 'anomaly', 'error']):
            model = IsolationForest(contamination=0.01, random_state=42)
            data_fit = self.df[[self.target]].fillna(0) # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ÙƒØ´Ù Ø§Ù„Ø£Ø¯Ù‚
            preds = model.fit_predict(data_fit)
            anomalies = self.df[preds == -1]
            
            if not anomalies.empty:
                fig = go.Figure(data=[go.Table(
                    header=dict(values=list(anomalies.columns), fill_color='red', font=dict(color='white')),
                    cells=dict(values=[anomalies[k].tolist() for k in anomalies.columns])
                )])
                return f"ğŸš¨ **ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:** ÙˆØ¬Ø¯Øª {len(anomalies)} Ø¹Ù…Ù„ÙŠØ§Øª ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ© (Ø´Ø§Ø°Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹):", fig
            else:
                return "âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ù„ÙŠÙ…Ø© ØªÙ…Ø§Ù…Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø©.", None

        # --- ØªÙ‚Ø±ÙŠØ± Ø¹Ø§Ù… ---
        else:
            val = filtered_df[self.target].sum()
            count = len(filtered_df)
            msg = f"""
            ğŸ¤– **ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ {context}:**
            - **Ø§Ù„Ù‡Ø¯Ù:** {self.target}
            - **Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª:** {count}
            - **Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ:** {val:,.2f}
            
            ğŸ’¡ *Ø§Ø³Ø£Ù„Ù†ÙŠ: "Ø£ÙØ¶Ù„ Ù…Ù†ØªØ¬"ØŒ "ØªØ·ÙˆØ± Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª"ØŒ "Ù‡Ù„ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡ØŸ"*
            """
            return msg, None

# ==========================================
# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Main App Logic)
# ==========================================

# Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
if 'df' not in st.session_state: st.session_state.df = None
if 'analyst' not in st.session_state: st.session_state.analyst = None
if 'messages' not in st.session_state: 
    st.session_state.messages = [{"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ğŸ‘‹ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡ ÙÙˆØ±Ø§Ù‹."}]

st.title("ğŸ§  Enterprise AI Analyst")

# --- Sidebar (File Upload) ---
with st.sidebar:
    st.header("ğŸ“‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù (Excel/CSV)", type=['xlsx', 'csv'])
    
    if uploaded_file and st.session_state.df is None:
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            # Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Auto-ML)
            identifier = AutoIdentifier(df)
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.session_state.df = identifier.df # Ø§Ù„Ø¯Ø§ØªØ§ Ø¨Ø¹Ø¯ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            st.session_state.analyst = SmartAnalyst(st.session_state.df, identifier.roles)
            
            # Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ ØªÙˆØ¶Ø­ Ù…Ø§ ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡
            roles = identifier.roles
            welcome_msg = f"""
            **âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!**
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø±Ù‚Ù…ÙŠ (Ø§Ù„Ù‡Ø¯Ù): `{roles['target_col']}`
            - Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®: `{roles['date_col'] if roles['date_col'] else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}`
            - Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØµÙ†ÙŠÙ: `{len(roles['cat_cols'])}` Ø£Ø¹Ù…Ø¯Ø©.
            
            **Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¢Ù†!** ğŸš€
            """
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
            st.rerun()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {e}")

    if st.button("ğŸ”„ Ø¨Ø¯Ø¡ Ø¬Ø¯ÙŠØ¯"):
        st.session_state.df = None
        st.session_state.analyst = None
        st.session_state.messages = [{"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ğŸ‘‹ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡ ÙÙˆØ±Ø§Ù‹."}]
        st.rerun()

# --- Chat Interface ---

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for msg in st.session_state.messages:
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙØ§ØªØ§Ø± (Ø´ÙƒÙ„ Ø§Ù„Ø§ÙŠÙ‚ÙˆÙ†Ø©)
    avatar = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¥Ù† ÙˆØ¬Ø¯
        if "chart" in msg and msg["chart"]:
            st.plotly_chart(msg["chart"], use_container_width=True)

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ..."):
    if st.session_state.analyst:
        # 1. Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)

        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                response_text, chart = st.session_state.analyst.process_query(prompt)
                
                st.markdown(response_text)
                if chart:
                    st.plotly_chart(chart, use_container_width=True)
                
                # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                st.session_state.messages.append({"role": "assistant", "content": response_text, "chart": chart})
    else:
        st.error("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹!")
