import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import IsolationForest
from dateutil import parser
import re
import warnings

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ù†Ø¸Ø§ÙØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
warnings.filterwarnings('ignore')

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©
# ==========================================
st.set_page_config(
    page_title="Enterprise AI Analyst",
    layout="wide",
    page_icon="ğŸ¢",
    initial_sidebar_state="expanded"
)

# CSS Ù„ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„Ø´Ø§Øª Ù„ÙŠÙƒÙˆÙ† Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹
st.markdown("""
<style>
    .stChatMessage {border-radius: 10px; padding: 10px;}
    .stChatInput {position: fixed; bottom: 20px;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠ (Cognitive Engine)
# ==========================================
class AutoIdentifier:
    """
    ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ„Ø§Ø³ Ø¨Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
    """
    def __init__(self, df):
        self.df = df
        self.column_roles = {}
        self._detect_roles()

    def _detect_roles(self):
        """Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¯ÙˆØ§Ø±"""
        cols = self.df.columns
        
        # Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
        keywords = {
            'date': ['date', 'time', 'ØªØ§Ø±ÙŠØ®', 'ÙˆÙ‚Øª', 'Ø²Ù…Ù†', 'ÙŠÙˆÙ…', 'Ø´Ù‡Ø±', 'day', 'month', 'year'],
            'money': ['price', 'sales', 'amount', 'total', 'salary', 'revenue', 'profit', 'cost', 'balance', 
                      'Ø³Ø¹Ø±', 'Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ù…Ø¨Ù„Øº', 'Ø§Ø¬Ù…Ø§Ù„ÙŠ', 'Ø±Ø§ØªØ¨', 'Ø±Ø¨Ø­', 'ØªÙƒÙ„ÙØ©', 'Ø±ØµÙŠØ¯', 'Ù‚ÙŠÙ…Ø©', 'Ø¯Ø®Ù„'],
            'quantity': ['qty', 'quantity', 'stock', 'count', 'inventory', 'units', 
                         'ÙƒÙ…ÙŠØ©', 'Ø¹Ø¯Ø¯', 'Ù…Ø®Ø²ÙˆÙ†', 'ÙˆØ­Ø¯Ø§Øª'],
            'category': ['category', 'product', 'item', 'name', 'customer', 'employee', 'branch', 'region', 'status', 
                         'ÙØ¦Ø©', 'Ù…Ù†ØªØ¬', 'ØµÙ†Ù', 'Ø§Ø³Ù…', 'Ø¹Ù…ÙŠÙ„', 'Ù…ÙˆØ¸Ù', 'ÙØ±Ø¹', 'Ù…Ù†Ø·Ù‚Ø©', 'Ø­Ø§Ù„Ø©', 'Ù‚Ø³Ù…']
        }

        self.column_roles = {
            'date_col': None,
            'target_col': None,  # Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ù…Ø¨ÙŠØ¹Ø§Øª/Ø±Ø§ØªØ¨)
            'cat_cols': []       # Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
        }

        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
        for col in cols:
            col_lower = str(col).lower()
            if any(k in col_lower for k in keywords['date']) or pd.api.types.is_datetime64_any_dtype(self.df[col]):
                self.column_roles['date_col'] = col
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ØªØ§Ø±ÙŠØ® ÙØ¹Ù„ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©
                try:
                    self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
                except: pass
                break # Ù†ÙƒØªÙÙŠ Ø¨Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ ØªØ§Ø±ÙŠØ® Ù†Ø¬Ø¯Ù‡

        # 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø±Ù‚Ù…ÙŠØ© (Target)
        potential_targets = []
        for col in cols:
            col_lower = str(col).lower()
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠØ§Ù‹
            if pd.api.types.is_numeric_dtype(self.df[col]):
                # Ù†Ø±Ù‰ Ù‡Ù„ Ø§Ø³Ù…Ù‡ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ù…Ø§Ù„ Ø£Ùˆ ÙƒÙ…ÙŠØ©
                score = 0
                if any(k in col_lower for k in keywords['money']): score += 2
                if any(k in col_lower for k in keywords['quantity']): score += 1
                potential_targets.append((col, score))
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ù‚ÙˆÙ‰
        if potential_targets:
            potential_targets.sort(key=lambda x: x[1], reverse=True)
            self.column_roles['target_col'] = potential_targets[0][0]

        # 3. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª (Categories)
        for col in cols:
            if col == self.column_roles['date_col'] or col == self.column_roles['target_col']:
                continue
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ØµÙŠØ§Ù‹ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù…Ø¹Ù‚ÙˆÙ„ (Ø£Ù‚Ù„ Ù…Ù† 500) Ù†Ø¹ØªØ¨Ø±Ù‡ ØªØµÙ†ÙŠÙ
            if self.df[col].dtype == 'object' or pd.api.types.is_string_dtype(self.df[col]):
                if self.df[col].nunique() < 1000: 
                    self.column_roles['cat_cols'].append(col)

# ==========================================
# 3. Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø­Ù„Ù„ (Analytical Brain)
# ==========================================
class EnterpriseAI:
    def __init__(self, df, roles):
        self.df = df
        self.roles = roles
        self.date_col = roles['date_col']
        self.target = roles['target_col']
        self.cats = roles['cat_cols']

    def detect_anomalies(self):
        """ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©"""
        if not self.target: return pd.DataFrame()
        
        model = IsolationForest(contamination=0.02, random_state=42)
        data = self.df[[self.target]].fillna(0)
        preds = model.fit_predict(data)
        return self.df[preds == -1]

    def find_smart_filter(self, query):
        """Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        query_words = query.lower().split()
        filtered_df = self.df.copy()
        applied_filters = []

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
        for col in self.cats:
            for word in query_words:
                clean_word = re.sub(r'[^\w\s]', '', word)
                if len(clean_word) < 2: continue
                
                # Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙƒÙ‚ÙŠÙ…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙˆØ¯ØŸ
                mask = self.df[col].astype(str).str.contains(clean_word, case=False, na=False)
                if mask.any():
                    # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„ÙƒÙ„Ù…Ø© Ù„ÙŠØ³Øª Ù…Ø¬Ø±Ø¯ Ø­Ø±Ù Ø¬Ø±
                    if clean_word not in ['Ù…Ù†', 'ÙÙŠ', 'Ø¹Ù„Ù‰', 'the', 'in', 'at']:
                        filtered_df = filtered_df[mask]
                        applied_filters.append(f"{col}={clean_word}")

        return filtered_df, applied_filters

    def process_query(self, query):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙÙ‡Ù… Ø§Ù„Ù†ÙŠØ©"""
        df_filtered, filters = self.find_smart_filter(query)
        response = ""
        chart = None
        
        # ØªØ­Ø¯ÙŠØ¯ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø¯ÙŠØ« (Ø¹Ù† Ù…Ù† Ù†ØªØ­Ø¯Ø«ØŸ)
        context_msg = f" (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙÙ„ØªØ±: {' + '.join(filters)})" if filters else " (Ø¹Ù„Ù‰ ÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)"
        
        if not self.target:
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ Ø±Ø¦ÙŠØ³ÙŠ (Ù…Ø«Ù„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø£Ùˆ Ø§Ù„Ø±ÙˆØ§ØªØ¨) ÙÙŠ Ø§Ù„Ù…Ù„Ù ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù.", None

        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©: Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        if any(x in query for x in ['Ø§Ø¬Ù…Ø§Ù„ÙŠ', 'Ù…Ø¬Ù…ÙˆØ¹', 'total', 'sum', 'Ø­Ø¬Ù…', 'Ù‚ÙŠÙ…Ø©']):
            val = df_filtered[self.target].sum()
            response = f"ğŸ’° **Ø¥Ø¬Ù…Ø§Ù„ÙŠ {self.target}** {context_msg}:\n# {val:,.2f}"
            
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©: Ø§Ù„Ù…ØªÙˆØ³Ø·
        elif any(x in query for x in ['Ù…ØªÙˆØ³Ø·', 'Ù…Ø¹Ø¯Ù„', 'avg', 'average']):
            val = df_filtered[self.target].mean()
            response = f"ğŸ“Š **Ù…ØªÙˆØ³Ø· {self.target}** {context_msg}:\n# {val:,.2f}"

        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©: Ø§Ù„Ø£ÙØ¶Ù„/Ø§Ù„Ø£Ø¹Ù„Ù‰
        elif any(x in query for x in ['Ø§ÙØ¶Ù„', 'Ø§Ø¹Ù„Ù‰', 'Ø§ÙƒØ«Ø±', 'top', 'best', 'highest', 'max']):
            # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ ØªØµÙ†ÙŠÙ
            best_col = self.cats[0] if self.cats else None
            if best_col:
                grouped = df_filtered.groupby(best_col)[self.target].sum().sort_values(ascending=False).head(5)
                response = f"ğŸ† **Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡Ù‹ ÙÙŠ {best_col}**:\n"
                chart = px.bar(grouped, x=grouped.index, y=self.target, title=f"Top 5 {best_col}", color=self.target)
            else:
                val = df_filtered[self.target].max()
                response = f"ğŸš€ **Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ø³Ø¬Ù„Ø©** Ù‡ÙŠ: {val:,.2f}"

        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©: Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø²Ù…Ù†ÙŠ
        elif any(x in query for x in ['ØªØ·ÙˆØ±', 'Ø²Ù…Ù†', 'ØªØ§Ø±ÙŠØ®', 'trend', 'time', 'date', 'Ù…ØªÙ‰']) and self.date_col:
            # Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø± Ø£Ùˆ Ø§Ù„ÙŠÙˆÙ…
            df_filtered['Period'] = df_filtered[self.date_col].dt.to_period('M').astype(str)
            trend = df_filtered.groupby('Period')[self.target].sum().reset_index()
            response = f"ğŸ“ˆ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù€ {self.target}**:"
            chart = px.line(trend, x='Period', y=self.target, markers=True, title="Growth Over Time")

        # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©: Ø§Ù„Ø£Ø®Ø·Ø§Ø¡/Ø§Ù„Ø´ÙˆØ§Ø°
        elif any(x in query for x in ['Ø®Ø·Ø£', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø´Ø§Ø°', 'anomaly', 'error', 'weird']):
            anomalies = self.detect_anomalies()
            count = len(anomalies)
            if count > 0:
                response = f"ğŸš¨ **ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø°ÙƒÙŠ:**\nØªÙ… Ø§ÙƒØªØ´Ø§Ù **{count}** Ø¹Ù…Ù„ÙŠØ§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ© ÙÙŠ Ø¹Ù…ÙˆØ¯ {self.target}.\nÙ‡Ø°Ù‡ Ø¹ÙŠÙ†Ø© Ù…Ù†Ù‡Ø§:"
                chart = go.Figure(data=[go.Table(
                    header=dict(values=list(anomalies.columns), fill_color='paleturquoise', align='left'),
                    cells=dict(values=[anomalies[k].tolist() for k in anomalies.columns], align='left'))
                ])
            else:
                response = "âœ… Ù‚Ù…Øª Ø¨Ø¹Ù…Ù„ Ù…Ø³Ø­ ÙƒØ§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹."

        # 6. ØªÙ‚Ø±ÙŠØ± Ø¹Ø§Ù… (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        else:
            total = df_filtered[self.target].sum()
            count = len(df_filtered)
            response = f"""
            ğŸ¤– **ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±ÙŠ {context_msg}:**
            - **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø­Ù„Ù„:** {self.target}
            - **Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª:** {count}
            - **Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ:** {total:,.2f}
            
            ğŸ’¡ *Ø£Ù†Ø§ ØªØ¹Ø±ÙØª Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹. ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„ÙŠ Ø¹Ù†: "ØªØ·ÙˆØ± Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª"ØŒ "Ø£ÙØ¶Ù„ Ù…ÙˆØ¸Ù"ØŒ "Ù‡Ù„ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡".*
            """
            
        return response, chart

# ==========================================
# 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (UI)
# ==========================================

# Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© (Session State)
if 'df' not in st.session_state: st.session_state.df = None
if 'ai_brain' not in st.session_state: st.session_state.ai_brain = None
if 'messages' not in st.session_state: st.session_state.messages = []

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
st.title("ğŸ¤– Enterprise Data AI")
st.markdown("#### Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø°ÙƒÙŠ (Auto-Detect Mode)")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø±ÙØ¹ ÙÙ‚Ø·
with st.sidebar:
    st.header("ğŸ“‚ Ù…Ø±ÙƒØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØ§ØªØ±Ùƒ Ø§Ù„Ø¨Ø§Ù‚ÙŠ Ø¹Ù„ÙŠ (Excel/CSV)", type=['xlsx', 'csv'])
    
    if uploaded_file and st.session_state.df is None:
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            # 1. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØµÙ†Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
            identifier = AutoIdentifier(df)
            roles = identifier.column_roles
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            st.session_state.df = df
            st.session_state.ai_brain = EnterpriseAI(df, roles)
            
            # Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ Ø°ÙƒÙŠØ©
            detected_msg = f"""
            **ØªÙ… ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! ğŸ§ **
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: `{roles['target_col']}`
            - Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®: `{roles['date_col'] if roles['date_col'] else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}`
            - Ø¹Ø¯Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØµÙ†ÙŠÙ: {len(roles['cat_cols'])}
            """
            st.session_state.messages.append({"role": "assistant", "content": f"Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! {detected_msg}\nØ£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø£Ø³Ø¦Ù„Ø©."})
            st.rerun()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {e}")

    if st.button("ğŸ”„ ØªØµÙÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.df = None
        st.session_state.ai_brain = None
        st.session_state.messages = []
        st.rerun()

# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø§Øª
if st.session_state.df is not None:
    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "chart" in msg:
                st.plotly_chart(msg["chart"], use_container_width=True)

    # Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
    if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŒ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†ØŒ Ø§Ù„Ù…Ø®Ø²ÙˆÙ†ØŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡..."):
        # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©..."):
                brain = st.session_state.ai_brain
                response_text, chart = brain.process_query(prompt)
                
                st.markdown(response_text)
                if chart:
                    st.plotly_chart(chart, use_container_width=True)
                
                # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯
                msg_data = {"role": "assistant", "content": response_text}
                if chart: msg_data["chart"] = chart
                st.session_state.messages.append(msg_data)

else:
    # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¹Ù†Ø¯ ÙØªØ­ Ø§Ù„Ù…ÙˆÙ‚Ø¹
    st.info("ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹! Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØµÙ…Ù… Ù„Ù„Ø´Ø±ÙƒØ§Øª. ÙÙ‚Ø· Ø§Ø±ÙØ¹ Ù…Ù„Ù (Ù…Ø¨ÙŠØ¹Ø§ØªØŒ Ù…Ø®Ø²ÙˆÙ†ØŒ HR) ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨ÙÙ‡Ù…Ù‡ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø±Ø¯ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")
    st.markdown("""
    ### ğŸš€ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:
    - **Auto-Detect:** ÙŠÙƒØªØ´Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.
    - **Anomaly Detection:** ÙŠÙƒØ´Ù Ø§Ù„Ø§Ø­ØªÙŠØ§Ù„ ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡.
    - **Deep Context:** ÙŠÙÙ‡Ù… Ø§Ù„ÙÙ„Ø§ØªØ± (Ù…Ø«Ù„Ø§Ù‹: "Ù…Ø¨ÙŠØ¹Ø§Øª Ù‚Ø³Ù… Ø§Ù„ØµÙŠØ§Ù†Ø©").
    """)
