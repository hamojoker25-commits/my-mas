import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import IsolationForest
from thefuzz import process, fuzz
import re
import warnings

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
warnings.filterwarnings('ignore')

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
# ==========================================
st.set_page_config(
    page_title="AI Data Analyst Pro",
    layout="wide",
    page_icon="ğŸ§ ",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stChatInput {position: fixed; bottom: 20px; z-index: 1000;}
    .block-container {padding-bottom: 120px;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Deep AI Core)
# ==========================================
class DataBrain:
    def __init__(self, df):
        self.df = df.copy()
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        self.df.columns = [str(c).strip() for c in self.df.columns]
        
        # 1. ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Indexing)
        self.column_types = self._identify_columns()
        self.value_index = self._index_unique_values()

    def _identify_columns(self):
        """ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©"""
        roles = {'numeric': [], 'date': [], 'text': []}
        
        for col in self.df.columns:
            # Ù‡Ù„ Ù‡Ùˆ ØªØ§Ø±ÙŠØ®ØŸ
            if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                roles['date'].append(col)
            # Ù‡Ù„ Ù‡Ùˆ Ø±Ù‚Ù…ØŸ
            elif pd.api.types.is_numeric_dtype(self.df[col]):
                roles['numeric'].append(col)
            # Ø¥Ø°Ù† Ù‡Ùˆ Ù†Øµ
            else:
                roles['text'].append(col)
                
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§ÙƒØªØ´Ø§Ù ØªÙˆØ§Ø±ÙŠØ® Ù…Ø®ØªØ¨Ø¦Ø© ÙÙŠ Ù†ØµÙˆØµ
        for col in roles['text']:
            if 'date' in col.lower() or 'ØªØ§Ø±ÙŠØ®' in col or 'ÙˆÙ‚Øª' in col:
                try:
                    self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
                    if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                        roles['text'].remove(col)
                        roles['date'].append(col)
                except: pass
                
        return roles

    def _index_unique_values(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹"""
        index = {}
        for col in self.column_types['text']:
            # Ù†Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙˆÙ†Ù†Ø¸ÙÙ‡Ø§
            unique_vals = self.df[col].dropna().astype(str).unique()
            for val in unique_vals:
                # Ø§Ù„Ù…ÙØªØ§Ø­ Ù‡Ùˆ Ø§Ù„Ù‚ÙŠÙ…Ø©ØŒ ÙˆØ§Ù„Ù‚ÙŠÙ…Ø© Ù‡ÙŠ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯
                index[val.lower()] = col
        return index

    def normalize_text(self, text):
        """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„Ø¨Ø­Ø«"""
        text = str(text).lower()
        text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text) # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù
        text = re.sub(r'Ø©', 'Ù‡', text)     # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø©
        text = re.sub(r'Ù‰', 'ÙŠ', text)     # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙŠØ§Ø¡
        text = re.sub(r'[^\w\s]', '', text) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„Ø±Ù…ÙˆØ²
        return text

    def understand_query(self, query):
        """
        Ø§Ù„Ù…Ø® Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ: ÙŠÙÙ‡Ù… Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
        """
        query_norm = self.normalize_text(query)
        
        intent = {
            'operation': 'sum', # default
            'target_col': None,
            'filters': {},
            'group_by': None,
            'time_frame': None,
            'chart_type': None
        }

        # 1. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Operation)
        if any(x in query_norm for x in ['Ù…ØªÙˆØ³Ø·', 'Ù…Ø¹Ø¯Ù„', 'avg', 'average']): 
            intent['operation'] = 'mean'
        elif any(x in query_norm for x in ['Ø¹Ø¯Ø¯', 'count', 'ÙƒÙ…']): 
            intent['operation'] = 'count'
        elif any(x in query_norm for x in ['Ø§Ù‚ØµÙ‰', 'Ø§Ø¹Ù„Ù‰', 'Ø§ÙƒØ¨Ø±', 'max', 'best', 'top']): 
            intent['operation'] = 'max'
        elif any(x in query_norm for x in ['Ø§Ø¯Ù†Ù‰', 'Ø§Ù‚Ù„', 'Ø§ØµØºØ±', 'min', 'worst']): 
            intent['operation'] = 'min'
        elif any(x in query_norm for x in ['ØªØ·ÙˆØ±', 'Ù†Ù…Ùˆ', 'trend', 'line']): 
            intent['chart_type'] = 'line'
        elif any(x in query_norm for x in ['ØªÙˆØ²ÙŠØ¹', 'Ù†Ø³Ø¨Ø©', 'pie']): 
            intent['chart_type'] = 'pie'

        # 2. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù (Target Column)
        # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„
        best_score = 0
        for col in self.column_types['numeric']:
            col_norm = self.normalize_text(col)
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Fuzzy Matching Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©
            score = fuzz.partial_ratio(col_norm, query_norm)
            if score > 80 and score > best_score:
                intent['target_col'] = col
                best_score = score
        
        # Ù„Ùˆ Ù…Ù„Ù‚Ø§Ø´ Ø¹Ù…ÙˆØ¯ Ù…Ø­Ø¯Ø¯ØŒ Ø¨ÙŠØ§Ø®Ø¯ Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ ÙÙ„ÙˆØ³ Ø£Ùˆ ÙƒÙ…ÙŠØ©
        if not intent['target_col'] and self.column_types['numeric']:
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ "Sales", "Price", "Total"
            priority_cols = [c for c in self.column_types['numeric'] if any(x in c.lower() for x in ['sales', 'total', 'price', 'amount', 'Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ø³Ø¹Ø±', 'Ø§Ø¬Ù…Ø§Ù„ÙŠ'])]
            intent['target_col'] = priority_cols[0] if priority_cols else self.column_types['numeric'][0]

        # 3. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙÙ„Ø§ØªØ± (Filters) - Ø£Ø°ÙƒÙ‰ Ø¬Ø²Ø¡
        # ÙŠÙØ­Øµ ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù‡Ù„ Ù‡ÙŠ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙƒÙ‚ÙŠÙ…Ø© ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§ØŸ
        words = query.split()
        for word in words:
            word_clean = self.normalize_text(word)
            if len(word_clean) < 2: continue
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙÙ‡Ø±Ø³ Ø§Ù„Ù‚ÙŠÙ…
            # Ù†Ø³ØªØ®Ø¯Ù… process.extractOne Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù† Ø£Ù‚Ø±Ø¨ ÙƒÙ„Ù…Ø©
            matches = process.extractOne(word, self.value_index.keys(), scorer=fuzz.ratio)
            if matches and matches[1] > 85: # Ù„Ùˆ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø£Ø¹Ù„Ù‰ Ù…Ù† 85%
                found_val = matches[0]
                col_name = self.value_index[found_val]
                # Ù†Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ø¯Ø§ØªØ§ ÙØ±ÙŠÙ…
                # (Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø§Ù„ØªÙŠ Ø·Ø§Ø¨Ù‚Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØµØºØ±Ø©)
                original_val = self.df[self.df[col_name].astype(str).str.lower() == found_val].iloc[0][col_name]
                intent['filters'][col_name] = original_val

        # 4. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Group By)
        # Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠÙ‡ "Ù„ÙƒÙ„ Ù…ÙˆØ¸Ù" Ø£Ùˆ "Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØªØ¬"
        if 'Ù„ÙƒÙ„' in query_norm or 'Ø­Ø³Ø¨' in query_norm or 'by' in query.lower():
            for col in self.column_types['text']:
                col_norm = self.normalize_text(col)
                if fuzz.partial_ratio(col_norm, query_norm) > 85:
                    intent['group_by'] = col
                    break
        
        return intent

    def execute_query(self, query):
        intent = self.understand_query(query)
        
        # 1. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
        filtered_df = self.df.copy()
        filter_desc = []
        for col, val in intent['filters'].items():
            filtered_df = filtered_df[filtered_df[col] == val]
            filter_desc.append(f"{col} = {val}")
        
        context_msg = f" (Ù„Ù€ {' Ùˆ '.join(filter_desc)})" if filter_desc else " (Ù„Ù„ÙƒÙ„)"
        target = intent['target_col']
        
        # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø®Ø§ØµØ© (Ø§Ù„Ø´ÙˆØ§Ø°)
        if any(x in query for x in ['Ø®Ø·Ø£', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø´Ø§Ø°', 'anomaly']):
            model = IsolationForest(contamination=0.01, random_state=42)
            data = self.df[[target]].fillna(0)
            preds = model.fit_predict(data)
            anomalies = self.df[preds == -1]
            return f"ğŸš¨ **ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:** ÙˆØ¬Ø¯Øª {len(anomalies)} Ø­Ø§Ù„Ø§Øª Ø´Ø§Ø°Ø© ÙÙŠ {target}.", anomalies

        # 3. ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª
        result_text = ""
        chart = None
        
        try:
            # Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Group By) Ø£Ùˆ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
            if intent['group_by'] or intent['chart_type'] or 'Ø§ÙØ¶Ù„' in query or 'top' in query:
                group_col = intent['group_by']
                
                # Ù„Ùˆ Ù…ÙÙŠØ´ Ø¹Ù…ÙˆØ¯ ØªØ¬Ù…ÙŠØ¹ Ù…Ø­Ø¯Ø¯ Ø¨Ø³ Ø·Ù„Ø¨ "Ø£ÙØ¶Ù„"ØŒ Ù†Ø®Ù…Ù† Ø¹Ù…ÙˆØ¯ ØªØµÙ†ÙŠÙ
                if not group_col and self.column_types['text']:
                    group_col = self.column_types['text'][0] # Ø§ÙØªØ±Ø§Ø¶
                
                if group_col:
                    grouped = filtered_df.groupby(group_col)[target].sum().sort_values(ascending=False)
                    
                    if 'Ø§ÙØ¶Ù„' in query or 'top' in query or 'max' in intent['operation']:
                        grouped = grouped.head(5)
                        title = f"ğŸ† Ø£ÙØ¶Ù„ 5 {group_col} Ø­Ø³Ø¨ {target}"
                    else:
                        grouped = grouped.head(10) # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 10 Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø²Ø­Ù…Ø©
                        title = f"ØªØ­Ù„ÙŠÙ„ {target} Ø­Ø³Ø¨ {group_col}"
                    
                    if intent['chart_type'] == 'pie':
                        chart = px.pie(names=grouped.index, values=grouped.values, title=title)
                    else:
                        chart = px.bar(x=grouped.index, y=grouped.values, title=title, labels={'x': group_col, 'y': target})
                    
                    result_text = f"ğŸ“Š **ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ {context_msg}:**\nØªÙ… Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ **{group_col}**. Ø§Ù†Ø¸Ø± Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ."
            
            # Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø²Ù…Ù†ÙŠ
            elif intent['chart_type'] == 'line' and self.column_types['date']:
                date_col = self.column_types['date'][0]
                # Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ù‡Ø±ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                trend = filtered_df.set_index(date_col).resample('M')[target].sum().reset_index()
                chart = px.line(trend, x=date_col, y=target, title=f"ØªØ·ÙˆØ± {target} Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†")
                result_text = f"ğŸ“ˆ **Ø§Ù„ØªØ±ÙŠÙ†Ø¯ Ø§Ù„Ø²Ù…Ù†ÙŠ {context_msg}:**"

            # Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© (Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯)
            else:
                val = 0
                op_name = ""
                if intent['operation'] == 'sum':
                    val = filtered_df[target].sum()
                    op_name = "Ø¥Ø¬Ù…Ø§Ù„ÙŠ"
                elif intent['operation'] == 'mean':
                    val = filtered_df[target].mean()
                    op_name = "Ù…ØªÙˆØ³Ø·"
                elif intent['operation'] == 'max':
                    val = filtered_df[target].max()
                    op_name = "Ø£Ù‚ØµÙ‰"
                elif intent['operation'] == 'min':
                    val = filtered_df[target].min()
                    op_name = "Ø£Ø¯Ù†Ù‰"
                elif intent['operation'] == 'count':
                    val = len(filtered_df)
                    op_name = "Ø¹Ø¯Ø¯"
                
                result_text = f"ğŸ”¢ **Ø§Ù„Ù†ØªÙŠØ¬Ø© {context_msg}:**\n{op_name} **{target}** = `{val:,.2f}`"

        except Exception as e:
            result_text = f"âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø³Ø§Ø¨. ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ '{target}' ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù….\n(Ø§Ù„Ø®Ø·Ø£: {str(e)})"

        return result_text, chart

# ==========================================
# 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ==========================================
st.title("ğŸ¤– Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø­Ù„Ù„ (AI Brain)")

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ“‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù (Excel/CSV)", type=['xlsx', 'csv'])
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø®
            if 'brain' not in st.session_state or st.session_state.last_file != uploaded_file.name:
                st.session_state.brain = DataBrain(df)
                st.session_state.last_file = uploaded_file.name
                st.session_state.messages = [{"role": "assistant", "content": f"âœ… ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆÙÙ‡Ø±Ø³Ø© {len(df)} Ø³Ø¬Ù„.\nØ£Ù†Ø§ Ø¬Ø§Ù‡Ø²! Ø¬Ø±Ø¨ ØªÙ‚ÙˆÙ„: 'Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ø­Ù…Ø¯' Ø£Ùˆ 'Ø£ÙØ¶Ù„ Ù…Ù†ØªØ¬' Ø£Ùˆ 'ØªØ·ÙˆØ± Ø§Ù„Ø£Ø±Ø¨Ø§Ø­'."}]
                st.rerun()
                
        except Exception as e:
            st.error("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù.")

    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- Chat Logic ---
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ø§Ù‹ ğŸ‘‹ Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø£Ùˆ Ø§Ù„ÙØµØ­Ù‰."}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "chart" in msg and msg["chart"] is not None:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¯Ø§ØªØ§ ÙØ±ÙŠÙ… (Ù„Ù„Ø£Ø®Ø·Ø§Ø¡) Ø£Ùˆ Ø±Ø³Ù… (Plotly)
            if isinstance(msg["chart"], pd.DataFrame):
                st.dataframe(msg["chart"])
            else:
                st.plotly_chart(msg["chart"], use_container_width=True)

if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..."):
    if 'brain' in st.session_state:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                response, chart = st.session_state.brain.execute_query(prompt)
                st.markdown(response)
                if chart is not None:
                    if isinstance(chart, pd.DataFrame):
                        st.dataframe(chart)
                    else:
                        st.plotly_chart(chart, use_container_width=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response, "chart": chart})
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹!")
